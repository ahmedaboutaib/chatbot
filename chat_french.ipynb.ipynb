{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot en Langue Française\n",
    "\n",
    "Ce code implémente un **chatbot en français** en utilisant un modèle d'encodeur-décodeur (Encoder-Decoder) basé sur des réseaux de neurones récurrents (LSTM). Le chatbot est capable de répondre à des questions en français en se basant sur un dataset de questions-réponses, avec une interface graphique pour interagir facilement.\n",
    "\n",
    "### Fonctionnement du Code\n",
    "\n",
    "1. **Chargement du Dataset** :\n",
    "   - Le dataset \"CATIE-AQ/frenchQA\" est utilisé, contenant des questions-réponses en français.\n",
    "   - Les données sont extraites et limitées à 5000 échantillons pour faciliter l'entraînement.\n",
    "\n",
    "2. **Prétraitement des Données** :\n",
    "   - Les questions et réponses sont tokenisées, c'est-à-dire transformées en séquences numériques. \n",
    "   - Les séquences sont ensuite alignées à la même longueur via du **padding** pour assurer une entrée uniforme dans le modèle.\n",
    "   - Les réponses sont formatées avec des tokens spéciaux (`<START>`, `<END>`) pour indiquer les débuts et fins de phrases.\n",
    "\n",
    "3. **Définition du Modèle** :\n",
    "   - Le modèle suit une architecture **encodeur-décodeur** :\n",
    "     - L'encodeur (basé sur LSTM) prend en entrée les questions et génère des états internes représentant l'information.\n",
    "     - Le décodeur (également basé sur LSTM) génère les réponses à partir des états de l'encodeur et d'une entrée initiale.\n",
    "   - L'entraînement est effectué avec une perte **categorical_crossentropy** et l'optimiseur RMSprop sur 100 epochs.\n",
    "\n",
    "4. **Sauvegarde et Chargement des Modèles** :\n",
    "   - Les modèles d'encodeur et décodeur sont sauvegardés après l'entraînement pour être utilisés dans l'interface de chat.\n",
    "   - Ces modèles sont ensuite chargés pour répondre aux questions posées par l'utilisateur.\n",
    "\n",
    "5. **Interface Graphique (GUI)** :\n",
    "   - Le code inclut une interface utilisateur construite avec **Tkinter**, permettant d'interagir avec le chatbot.\n",
    "   - L'utilisateur entre une question dans une boîte de texte, et le chatbot génère une réponse qui s'affiche dans la zone de dialogue.\n",
    "\n",
    "### Structure du Modèle\n",
    "\n",
    "- **Encodeur** : Prend les questions en entrée et extrait des représentations vectorielles.\n",
    "- **Décodeur** : Génère des réponses basées sur les états internes de l'encodeur et les tokens de début/fin.\n",
    "- **Entraînement** : Utilise la méthode de **teacher forcing** pour améliorer l'apprentissage des séquences cibles.\n",
    "\n",
    "### Objectif\n",
    "\n",
    "Ce code constitue un point de départ pour créer un **chatbot en langue française** basé sur des réseaux de neurones séquentiels. Il peut être adapté à divers autres datasets ou langues, en ajustant les données d'entrée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset french_qa (C:\\Users\\user\\.cache\\huggingface\\datasets\\CATIE-AQ___french_qa\\frenchQA\\1.0.0\\4e913172efd12edfd4088c875a8864a8315c40f517d8ec5c50e3dbdfdb268a3a)\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'title': 'pragnakalp/squad_v2_french_translated', 'context': \"Beyoncé Giselle Knowles-Carter (/ biːˈjɒnseɪ / bee-YON-say) (née le 4 septembre 1981) est une chanteuse, compositrice, productrice de disques et actrice américaine. Née et élevée à Houston, au Texas, elle a joué dans divers chant et danse enfant, et est devenu célèbre à la fin des années 1990 en tant que chanteuse du groupe de filles R&B Destiny's Child. Géré par son père, Mathew Knowles, le groupe est devenu l'un des groupes de filles les plus vendus au monde de tous les temps. a vu la sortie du premier album de Beyoncé, Dangerously in Love (2003), qui l'a établie en tant qu'artiste solo dans le monde entier, a remporté cinq Grammy Awards et a présenté les singles numéro un du Billboard Hot 100 Crazy in Love et Baby Boy.\", 'question': 'Quand Beyonce a-t-elle commencé à devenir populaire ?', 'answers': {'text': ['à la fin des années 1990'], 'answer_start': [269]}}\n",
      "<class 'str'>\n",
      "200617\n",
      "200617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "from keras import layers, models, activations, optimizers\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Chargement du dataset \"CATIE-AQ/frenchQA\" contenant des questions et réponses en français\n",
    "dataset = load_dataset(\"CATIE-AQ/frenchQA\")\n",
    "\n",
    "# Affichage d'un exemple de données du dataset pour observer la structure des données\n",
    "print(dataset['train'][0])  \n",
    "\n",
    "# Séparation des données d'entraînement du dataset\n",
    "train = dataset[\"train\"]\n",
    "\n",
    "# Extraction des questions et des réponses\n",
    "questions = train[\"question\"]\n",
    "answ = train[\"answers\"]\n",
    "\n",
    "# Affichage du type des données pour une question et la taille des listes de questions et réponses\n",
    "print(type(questions[1]))\n",
    "print(len(questions))\n",
    "print(len(answ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation des données à 5000 échantillons pour éviter des temps de traitement trop longs\n",
    "questions = questions[:1499]\n",
    "answ = answ[:1499]\n",
    "\n",
    "# Préparation des réponses : On joint les textes de réponse en une seule chaîne de caractères\n",
    "answers = [\" \".join(ans['text']) for ans in answ]\n",
    "\n",
    "# Ajout d'un exemple de question et réponse \"bonjour\" à la liste pour vérification\n",
    "answers.append(\"bonjour\")\n",
    "questions.append(\"bonjour\")\n",
    "\n",
    "# Tokenization et padding des questions\n",
    "# Tokenizer transforme le texte en séquences d'entiers correspondant aux mots\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(questions)  # Apprentissage du dictionnaire de mots basé sur les questions\n",
    "encoded_questions = tokenizer.texts_to_sequences(questions)  # Conversion des questions en séquences numériques\n",
    "\n",
    "# Calcul de la longueur maximale d'une question pour uniformiser la taille des séquences\n",
    "max_len_q = max(len(seq) for seq in encoded_questions)\n",
    "\n",
    "# Application de padding (complètement des séquences avec des zéros) pour aligner les questions à la même longueur\n",
    "padded_questions = preprocessing.sequence.pad_sequences(encoded_questions, maxlen=max_len_q, padding='pre')\n",
    "\n",
    "# Extraction du dictionnaire des mots pour les questions (mots associés à des indices numériques)\n",
    "question_word_dict = tokenizer.word_index\n",
    "\n",
    "# Préparation des réponses avec des tokens spéciaux \"<START>\" et \"<END>\" pour le modèle séquentiel\n",
    "decoder_answers = ['<START>' + str(ans) + ' <END>' for ans in answers]\n",
    "\n",
    "# Re-apprentissage du tokenizer sur les réponses formatées avec les tokens spéciaux\n",
    "tokenizer.fit_on_texts(decoder_answers)\n",
    "encoded_answers = tokenizer.texts_to_sequences(decoder_answers)  # Conversion des réponses en séquences numériques\n",
    "\n",
    "# Calcul de la longueur maximale d'une réponse\n",
    "max_len_a = max(len(seq) for seq in encoded_answers)\n",
    "\n",
    "# Application de padding sur les réponses pour aligner les longueurs des séquences\n",
    "padded_answers = preprocessing.sequence.pad_sequences(encoded_answers, maxlen=max_len_a, padding='post')\n",
    "\n",
    "# Extraction du dictionnaire des mots pour les réponses\n",
    "answer_word_dict = tokenizer.word_index\n",
    "\n",
    "# Préparation des données cibles du décodeur : Décalage des réponses pour servir de cible lors de l'entraînement\n",
    "decoder_target_data = [seq[1:] for seq in encoded_answers]\n",
    "\n",
    "# Application de padding pour les séquences cibles et transformation en encodage one-hot pour classification\n",
    "decoder_target_data = preprocessing.sequence.pad_sequences(decoder_target_data, maxlen=max_len_a, padding='post')\n",
    "decoder_target_data = utils.to_categorical(np.array(decoder_target_data), len(answer_word_dict) + 1)\n",
    "\n",
    "# Définition du modèle d'encodeur-décodeur\n",
    "# Calcul du nombre de tokens uniques (mots) pour les questions et les réponses\n",
    "question_tokens = len(question_word_dict) + 1\n",
    "answer_tokens = len(answer_word_dict) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation et Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">610,800</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">749,000</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ embedding_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>),      │            │ not_equal_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ embedding_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">752,745</span> │ lstm_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3745</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │    \u001b[38;5;34m610,800\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │    \u001b[38;5;34m749,000\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_26 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m),     │    \u001b[38;5;34m320,800\u001b[0m │ embedding_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m),      │            │ not_equal_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_27 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m320,800\u001b[0m │ embedding_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │    \u001b[38;5;34m752,745\u001b[0m │ lstm_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m3745\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,754,145</span> (10.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,754,145\u001b[0m (10.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,754,145</span> (10.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,754,145\u001b[0m (10.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = layers.Input(shape=(None,))\n",
    "encoder_embedding = layers.Embedding(input_dim=question_tokens, output_dim=200, mask_zero=True)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(200, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "decoder_embedding = layers.Embedding(input_dim=answer_tokens, output_dim=200, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(200, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(answer_tokens, activation=activations.softmax)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Compile and train the model\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\github\\chat\\chat1\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_169', 'keras_tensor_175']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 435ms/step - accuracy: 0.7231 - loss: 7.7283\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 436ms/step - accuracy: 0.8329 - loss: 4.6309\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486ms/step - accuracy: 0.8369 - loss: 4.3901\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 480ms/step - accuracy: 0.3047 - loss: 4.1396\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 484ms/step - accuracy: 0.1246 - loss: 3.9864\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 504ms/step - accuracy: 0.1248 - loss: 3.8759\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 507ms/step - accuracy: 0.1249 - loss: 3.7917\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 501ms/step - accuracy: 0.1250 - loss: 3.8156\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.1250 - loss: 3.7784\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 484ms/step - accuracy: 0.1249 - loss: 3.7166\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 491ms/step - accuracy: 0.1250 - loss: 3.6856\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 490ms/step - accuracy: 0.1250 - loss: 3.6519\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 488ms/step - accuracy: 0.1250 - loss: 3.7022\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.1250 - loss: 3.6330\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486ms/step - accuracy: 0.1250 - loss: 3.6038\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 491ms/step - accuracy: 0.1250 - loss: 3.6541\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 487ms/step - accuracy: 0.1250 - loss: 3.5396\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 487ms/step - accuracy: 0.1250 - loss: 3.5464\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 482ms/step - accuracy: 0.1250 - loss: 3.6043\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 498ms/step - accuracy: 0.1250 - loss: 3.5398\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 497ms/step - accuracy: 0.1250 - loss: 3.5548\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 473ms/step - accuracy: 0.1250 - loss: 3.5850\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 476ms/step - accuracy: 0.1250 - loss: 3.5726\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474ms/step - accuracy: 0.1250 - loss: 3.5317\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.1250 - loss: 3.4849\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 473ms/step - accuracy: 0.1250 - loss: 3.5386\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 475ms/step - accuracy: 0.1250 - loss: 3.4996\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474ms/step - accuracy: 0.1250 - loss: 3.4767\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 474ms/step - accuracy: 0.1250 - loss: 3.4484\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 471ms/step - accuracy: 0.1250 - loss: 3.5114\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474ms/step - accuracy: 0.1250 - loss: 3.5015\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 476ms/step - accuracy: 0.1250 - loss: 3.4849\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 476ms/step - accuracy: 0.1250 - loss: 3.4718\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 483ms/step - accuracy: 0.1250 - loss: 3.4364\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 515ms/step - accuracy: 0.1250 - loss: 3.4202\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.1250 - loss: 3.3899\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 471ms/step - accuracy: 0.1250 - loss: 3.3836\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 473ms/step - accuracy: 0.1250 - loss: 3.3921\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 468ms/step - accuracy: 0.1250 - loss: 3.3866\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 486ms/step - accuracy: 0.1250 - loss: 3.3838\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 464ms/step - accuracy: 0.1250 - loss: 3.3466\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 470ms/step - accuracy: 0.1250 - loss: 3.3241\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 464ms/step - accuracy: 0.1250 - loss: 3.3125\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 469ms/step - accuracy: 0.1251 - loss: 3.2917\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 463ms/step - accuracy: 0.1250 - loss: 3.2817\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 466ms/step - accuracy: 0.1251 - loss: 3.2499\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 472ms/step - accuracy: 0.1255 - loss: 3.2341\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 467ms/step - accuracy: 0.1252 - loss: 3.2332\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 465ms/step - accuracy: 0.1252 - loss: 3.2262\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 472ms/step - accuracy: 0.1256 - loss: 3.2300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a1d0f6a710>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([padded_questions, padded_answers], decoder_target_data, batch_size=64, epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde et Chargement des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "def create_encoder_decoder_models():\n",
    "    encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "    decoder_input_state_h = layers.Input(shape=(200,))\n",
    "    decoder_input_state_c = layers.Input(shape=(200,))\n",
    "    decoder_input_states = [decoder_input_state_h, decoder_input_state_c]\n",
    "    decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding, initial_state=decoder_input_states)\n",
    "    decoder_output_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "    decoder_model = models.Model(\n",
    "        [decoder_inputs] + decoder_input_states, [decoder_outputs] + decoder_output_states)\n",
    "    return encoder_model, decoder_model\n",
    "\n",
    "enc_model, dec_model = create_encoder_decoder_models()\n",
    "enc_model.save('model/encoder_model_batsh_8.keras')\n",
    "dec_model.save('model/decoder_model_batsh_8.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Interface Utilisateur (GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras as k\n",
    "import string\n",
    "\n",
    "# Load pre-trained models\n",
    "enc_model = k.models.load_model('model/encoder_model_batsh_8.keras', compile=False)\n",
    "dec_model = k.models.load_model('model/decoder_model_batsh_8.keras', compile=False)\n",
    "\n",
    "# Helper function to convert question to tokens\n",
    "def question_to_tokens(question, max_len, question_word_dict):\n",
    "    question = question.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    tokens = [question_word_dict.get(word, 0) for word in question]\n",
    "    return pad_sequences([tokens], maxlen=max_len, padding='post')\n",
    "\n",
    "# Function to generate responses from chatbot\n",
    "def getResponse(question, enc_model, dec_model, max_len_q, answer_word_dict):\n",
    "    states_values = enc_model.predict(question_to_tokens(question, max_len_q, question_word_dict))\n",
    "    token = np.zeros((1, 1))\n",
    "    token[0, 0] = answer_word_dict['start']\n",
    "    \n",
    "    stop_condition = False\n",
    "    chatbot_answer = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        dec_output, h, c = dec_model.predict([token] + states_values)\n",
    "        index = np.argmax(dec_output[0, 0, :])\n",
    "        word = list(answer_word_dict.keys())[index - 1]\n",
    "        \n",
    "        # Stop if the word is 'end' but don't add 'end' to the answer\n",
    "        if word == 'end' or len(chatbot_answer.split()) > max_len_a:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            chatbot_answer += ' ' + word\n",
    "            \n",
    "        token[0, 0] = index\n",
    "        states_values = [h, c]\n",
    "    \n",
    "    return chatbot_answer.strip()\n",
    "\n",
    "# Chatbot GUI using Tkinter\n",
    "def chatting():\n",
    "    sen = entryBox.get('1.0', END).strip()\n",
    "    entryBox.delete('1.0', END)\n",
    "    chatArea.config(state=NORMAL)\n",
    "    chatArea.insert(END, \"You: \" + sen + \"\\n\\n\")\n",
    "    res = getResponse(sen, enc_model, dec_model, max_len_q, answer_word_dict)\n",
    "    chatArea.insert(END, \"Bot: \" + res + \"\\n\\n\")\n",
    "    chatArea.yview(END)\n",
    "    chatArea.config(state=DISABLED)\n",
    "\n",
    "# Initialize GUI\n",
    "gui = Tk()\n",
    "gui.title('ChatBot')\n",
    "gui.geometry('400x500')\n",
    "gui.resizable(width=False, height=False)\n",
    "\n",
    "# Add GUI elements\n",
    "chatArea = Text(gui, font=('Arial', 12))\n",
    "chatArea.config(state=DISABLED)\n",
    "scrollBar = Scrollbar(gui, command=chatArea.yview)\n",
    "chatArea['yscrollcommand'] = scrollBar.set\n",
    "chatButton = Button(gui, bd=0, command=chatting, text='Send', fg='white', font=('Arial', 18, 'bold'), bg='darkorange')\n",
    "entryBox = Text(gui, font=('Arial', 12), height=2)\n",
    "\n",
    "# Place components in the window\n",
    "chatArea.place(x=6, y=6, height=380, width=380)\n",
    "scrollBar.place(x=380, y=6, height=380, width=20)\n",
    "chatButton.place(x=6, y=400, height=90)\n",
    "entryBox.place(x=110, y=400, height=90, width=280)\n",
    "\n",
    "# Run the GUI loop\n",
    "gui.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow.keras import preprocessing, utils\n",
    "# from keras import layers, models, activations, optimizers\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Charger le dataset\n",
    "# dataset = load_dataset(\"CATIE-AQ/frenchQA\")\n",
    "# train = dataset[\"train\"]\n",
    "# questions = train[\"question\"]\n",
    "# answ = train[\"answers\"]\n",
    "\n",
    "# # Limiter la taille des données pour l'exemple\n",
    "# questions = questions[:3000]\n",
    "# answ = answ[:3000]\n",
    "\n",
    "# # Preprocessing des réponses\n",
    "# answers = [\" \".join(ans['text']) for ans in answ]\n",
    "# answers = ['<START> ' + ans + ' <END>' for ans in answers]\n",
    "\n",
    "# # Tokenisation et padding des questions\n",
    "# tokenizer = preprocessing.text.Tokenizer()\n",
    "# tokenizer.fit_on_texts(questions)\n",
    "# encoded_questions = tokenizer.texts_to_sequences(questions)\n",
    "# max_len_q = max(len(seq) for seq in encoded_questions)\n",
    "# padded_questions = preprocessing.sequence.pad_sequences(encoded_questions, maxlen=max_len_q, padding='pre')\n",
    "# question_word_dict = tokenizer.word_index\n",
    "\n",
    "# # Tokenisation et padding des réponses\n",
    "# tokenizer.fit_on_texts(answers)\n",
    "# encoded_answers = tokenizer.texts_to_sequences(answers)\n",
    "# max_len_a = max(len(seq) for seq in encoded_answers)\n",
    "# padded_answers = preprocessing.sequence.pad_sequences(encoded_answers, maxlen=max_len_a, padding='post')\n",
    "# answer_word_dict = tokenizer.word_index\n",
    "\n",
    "# # Préparer les données cibles pour le décodeur\n",
    "# decoder_target_data = [seq[1:] for seq in encoded_answers]\n",
    "# decoder_target_data = preprocessing.sequence.pad_sequences(decoder_target_data, maxlen=max_len_a, padding='post')\n",
    "# decoder_target_data = utils.to_categorical(np.array(decoder_target_data), len(answer_word_dict) + 1)\n",
    "\n",
    "# # Taille des vocabulaires\n",
    "# question_tokens = len(question_word_dict) + 1\n",
    "# answer_tokens = len(answer_word_dict) + 1\n",
    "\n",
    "# # Encoder\n",
    "# encoder_inputs = layers.Input(shape=(None,))\n",
    "# encoder_embedding = layers.Embedding(input_dim=question_tokens, output_dim=128, mask_zero=True)(encoder_inputs)\n",
    "# encoder_outputs, state_h, state_c = layers.LSTM(128, return_state=True, return_sequences=True)(encoder_embedding)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Decoder avec Attention\n",
    "# decoder_inputs = layers.Input(shape=(None,))\n",
    "# decoder_embedding = layers.Embedding(input_dim=answer_tokens, output_dim=128, mask_zero=True)(decoder_inputs)\n",
    "# decoder_lstm = layers.LSTM(128, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# # Transformer les sorties de l'encodeur pour s'aligner sur les sorties du décodeur\n",
    "# encoder_dense = layers.Dense(128)(encoder_outputs)\n",
    "\n",
    "# # Appliquer l'attention après la transformation\n",
    "# attention = layers.Attention()([decoder_outputs, encoder_dense])\n",
    "# decoder_concat_input = layers.Concatenate(axis=-1)([decoder_outputs, attention])\n",
    "\n",
    "# # Couche de sortie\n",
    "# decoder_dense = layers.Dense(answer_tokens, activation=activations.softmax)\n",
    "# decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# # Compilation du modèle\n",
    "# model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# # Entraîner le modèle\n",
    "# model.fit([padded_questions, padded_answers], decoder_target_data, batch_size=32, epochs=50)\n",
    "\n",
    "# # Fonction de sauvegarde des modèles encodeur/décodeur\n",
    "# def create_encoder_decoder_models():\n",
    "#     encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "#     decoder_state_input_h = layers.Input(shape=(128,))\n",
    "#     decoder_state_input_c = layers.Input(shape=(128,))\n",
    "#     decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "#     dec_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_state_inputs)\n",
    "#     attention_inf = layers.Attention()([dec_outputs, encoder_dense])\n",
    "#     decoder_concat_inf = layers.Concatenate(axis=-1)([dec_outputs, attention_inf])\n",
    "#     dec_outputs = decoder_dense(decoder_concat_inf)\n",
    "    \n",
    "#     decoder_model = models.Model(\n",
    "#         [decoder_inputs] + decoder_state_inputs, [dec_outputs] + [state_h, state_c]\n",
    "#     )\n",
    "    \n",
    "#     return encoder_model, decoder_model\n",
    "\n",
    "# # Sauvegarder les modèles\n",
    "# enc_model, dec_model = create_encoder_decoder_models()\n",
    "# enc_model.save('model/encoder_model.keras')\n",
    "# dec_model.save('model/decoder_model.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
